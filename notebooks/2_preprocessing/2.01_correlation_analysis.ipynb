{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing\n",
    "## 2.01 Variable selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear correlation**\n",
    "\n",
    "We want to shortly investigate which features might carry the most potential for use in the flood model. \n",
    "In order to do this, we evaluate the correlation between a the upstream mean of an ERA5 variable or a derived variable against discharge at an example river gridpoint.\n",
    "Thus, we are comparing time series of predictor variables with timeseries of the predictand.\n",
    "\n",
    "As we want to limit the features for the LocalModel, which is supposed to predict the leftover residuals from the TransportModel mainly consisting of the local impacts arising from precipitation and other corresponding variables, we filter the data in the time dimension to only incude days with measurable amounts of precipitation recorded and furthermore look at the change of discharge from one day to another, instead of absolute values.\n",
    "\n",
    "To quantify the impact of each feature, we use a filter method with the pearson correlation coefficient.\n",
    "\n",
    "The point of interest shall be `latitude=48.35, longitude=13.95`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to import custom functions, we need to add the repository path to the system's python path with `sys.path.append('../../')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python.aux.utils_floodmodel import get_mask_of_basin, add_shifted_variables, reshape_scalar_predictand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:      (latitude: 13, longitude: 25, time: 5478)\n",
       "Coordinates:\n",
       "  * time         (time) datetime64[ns] 1981-01-01 1981-01-02 ... 1995-12-31\n",
       "  * longitude    (longitude) float32 8.0 8.25 8.5 8.75 ... 13.25 13.5 13.75 14.0\n",
       "  * latitude     (latitude) float32 50.0 49.75 49.5 49.25 ... 47.5 47.25 47.0\n",
       "Data variables:\n",
       "    cp           (time, latitude, longitude) float32 ...\n",
       "    lsp          (time, latitude, longitude) float32 ...\n",
       "    swvl1        (time, latitude, longitude) float32 ...\n",
       "    tcwv         (time, latitude, longitude) float32 ...\n",
       "    ro           (time, latitude, longitude) float32 ...\n",
       "    rtp_500-850  (time, latitude, longitude) float32 ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "era5 = xr.open_dataset('../../data/smallsampledata-era5.nc')\n",
    "glofas = xr.open_dataset('../../data/smallsampledata-glofas.nc')\n",
    "era5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: `rtp_500-850` is the **relative topography**, a derived variable by subtracting the geopotential in 850 hPa from the geopotential height in 500 hPa, i.e. `era5['z'].sel(level=500)-era5['z'].sel(level=850)`. It is proportional to the mass weighted (=barometric) mean temperature between those levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_preproc(era5, glofas, timeinit, timeend):\n",
    "\n",
    "    features = ['cp', 'lsp', 'ro', 'rtp_500-850', 'tcwv', 'swvl1']\n",
    "    era5_features = era5[features]\n",
    "\n",
    "    # interpolate to glofas grid\n",
    "    era5_features = era5_features.interp(latitude=glofas.latitude,\n",
    "                                         longitude=glofas.longitude)\n",
    "    # time subset\n",
    "    era5_features = era5_features.sel(time=slice(timeinit, timeend))\n",
    "    glofas = glofas.sel(time=slice(timeinit, timeend))\n",
    "\n",
    "    # select the point of interest\n",
    "    #poi = dict(latitude=48.403, longitude=15.615)  # krems (lower austria)\n",
    "    poi = dict(latitude=48.35, longitude=13.95)  # point in upper austria\n",
    "\n",
    "    dummy = glofas['dis'].isel(time=0)\n",
    "    danube_catchment = get_mask_of_basin(dummy, kw_basins='Danube')\n",
    "    X = era5_features.where(danube_catchment).mean(['latitude', 'longitude'])\n",
    "\n",
    "    # select area of interest and average over space for all features\n",
    "    dis = glofas.interp(poi)\n",
    "    y = dis.diff('time', 1)  # compare predictors to change in discharge\n",
    "    \n",
    "    shifts = range(1,3)\n",
    "    notshift_vars = ['swvl1', 'tcwv', 'rtp_500-850']\n",
    "    shift_vars = [v for v in X.data_vars if not v in notshift_vars]\n",
    "\n",
    "    X = add_shifted_variables(X, shifts, variables=shift_vars)\n",
    "    \n",
    "    Xda, yda = reshape_scalar_predictand(X, y)  # reshape into dimensions (time, feature)\n",
    "    return Xda, yda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "def generate_heatmap(X, y, descr='description'):\n",
    "    df = pd.DataFrame(data=X.T.values, columns=X.features.values, index=X.time.values)\n",
    "    df['predictand'] = y\n",
    "    plt.figure(figsize=(25,25))\n",
    "    cor = df.corr()\n",
    "    sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "    plt.show()\n",
    "    cor_predictand = abs(cor['predictand'])\n",
    "    feature_importance = cor_predictand[cor_predictand > 0.2]\n",
    "    print(descr)\n",
    "    print(feature_importance)\n",
    "    return feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all methods are set up, lets have a look at different time periods and generate a correlation heatmap between all features, with a printed list of features >0.2 correlation coeff at the end. Lets also save the important feature into a new list and evaluate it at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-35202d647b41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_preproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mera5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mera5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglofas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglofas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeinit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1980'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1984'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mXtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cp'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lsp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mXprecip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtp\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXprecip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-da02f657c3e3>\u001b[0m in \u001b[0;36mfeature_preproc\u001b[0;34m(era5, glofas, timeinit, timeend)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_shifted_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshifts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshift_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mXda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_scalar_predictand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# reshape into dimensions (time, feature)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mXda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "X, y = feature_preproc(era5=era5, glofas=glofas, timeinit='1980', timeend='1984')\n",
    "\n",
    "Xtp = X.sel(features='cp') + X.sel(features='lsp')\n",
    "Xprecip = Xtp.where(Xtp>1/1000, drop=True)\n",
    "X = X.where(Xprecip)\n",
    "y = y.where(Xprecip)\n",
    "\n",
    "ft = generate_heatmap(X=X, y=y, descr=f'{timeinit}-{timeend}; only days with precip > 1mm')\n",
    "important_features.append(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = feature_preproc(era5=era5, glofas=glofas, timeinit='1985', timeend='1989')\n",
    "Xtp = X.sel(features='cp') + X.sel(features='lsp')\n",
    "Xprecip = Xtp.where(Xtp>1/1000, drop=True)\n",
    "X = X.where(Xprecip)\n",
    "y = y.where(Xprecip)\n",
    "ft = generate_heatmap(X=X, y=y, descr=f'{timeinit}-{timeend}; only days with precip > 1mm')\n",
    "important_features.append(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = feature_preproc(era5=era5, glofas=glofas, timeinit='1990', timeend='1995')\n",
    "Xtp = X.sel(features='cp') + X.sel(features='lsp')\n",
    "Xprecip = Xtp.where(Xtp>1/1000, drop=True)\n",
    "X = X.where(Xprecip)\n",
    "y = y.where(Xprecip)\n",
    "ft = generate_heatmap(X=X, y=y, descr=f'{timeinit}-{timeend}; only days with precip > 1mm')\n",
    "important_features.append(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeinit = '1980-01-01'\n",
    "timeend = '2017-12-31'\n",
    "X, y = feature_preproc(era5=era5, glofas=glofas, timeinit=timeinit, timeend=timeend)\n",
    "Xtp = X.sel(features='cp') + X.sel(features='lsp')\n",
    "Xprecip = Xtp.where(Xtp>1/1000, drop=True)\n",
    "X = X.where(Xprecip)\n",
    "y = y.where(Xprecip)\n",
    "ft = generate_heatmap(X=X, y=y, descr=f'{timeinit}-{timeend}; only days with precip > 1mm')\n",
    "important_features.append(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at long periods of time the resulting feature importance is:\n",
    "\n",
    "cp, lsp, ro, cp-1, lsp-1, ro-1, swvl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in important_features:\n",
    "    print(entry[:-1])\n",
    "    print('#'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we look at a specific flooding example: May/June 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeinit = '2013-05-30'\n",
    "timeend = '2013-06-15'\n",
    "X, y = feature_preproc(era5=era5, glofas=glofas, timeinit=timeinit, timeend=timeend)\n",
    "Xtp = X.sel(features='cp') + X.sel(features='lsp')\n",
    "Xprecip = Xtp.where(Xtp>1/1000, drop=True)\n",
    "X = X.where(Xprecip)\n",
    "y = y.where(Xprecip)\n",
    "ft = generate_heatmap(X=X, y=y, descr=f'{timeinit}-{timeend}; only days with precip > 1mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft[ft > 0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the resulting features take on a different take. It is not suprising, that **cp** is not contained in the stricter requirement of coef > 0.6, because at the event in question, there was largerly orographically induced precipitation (so called, Nordstau), which is contributed as **lsp**.\n",
    "\n",
    "Additionally, **tcwv-1** and **tcwv-2** exhibit a hight correlation coefficient as well. But looking at inter-feature colinearity, we can quickly deduce that both of those variables are highly correlated with **lsp** as well (which makes perfect sense from a physical pov, due to the orographic induced lifting, moisturizing the atmosphere over extended periods of time), which means we can safely ignore those features, as their impact is already considered in **lsp**.\n",
    "\n",
    "Although the other features exhibit not insignificant colinearity as well, they do present a different physical process, which is why they should not be neglected just because of one examplary case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going forward, the most interesting features to capture for flooding seem to be **lsp**, **ro**, **swvl1** as well as time lagged **lsp** (an indication for large flooding events, due to extending periods with huge amounts of precipitation, as well as **cp** for flash floods (although this last relation has to be captured in a few case examples yet, but holds some weight in the overall influence shown above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
