{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Downloader for ERA5 and GLoFAS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defines some methods to download era5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import cdsapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-89ad931fed9e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-89ad931fed9e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    UID = #enter_uid_here\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "UID = #enter_uid_here\n",
    "API_key = #enter_key_here\n",
    "\n",
    "with open(os.path.join(os.path.expanduser('~'), '.cdsapirc'), 'w') as f:\n",
    "    f.write('url: https://cds.climate.copernicus.eu/api/v2\\n')\n",
    "    f.write(f'key: {UID}:{API_key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_request(kwargs, input_checking=True):                    \n",
    "                                  \n",
    "    mandatory_fields = [\"product_type\", \"format\", \"variable\", \"year\", \"month\"]\n",
    "    if not input_checking:\n",
    "        mandatory_fields = []\n",
    "    \n",
    "    assumed_args = {\"day\":    [\"01\", \"02\", \"03\", \"04\",\n",
    "                               \"05\", \"06\", \"07\", \"08\",\n",
    "                               \"09\", \"10\", \"11\", \"12\",\n",
    "                               \"13\", \"14\", \"15\", \"16\",\n",
    "                               \"17\", \"18\", \"19\", \"20\",\n",
    "                               \"21\", \"22\", \"23\", \"24\",\n",
    "                               \"25\", \"26\", \"27\", \"28\",\n",
    "                               \"29\", \"30\", \"31\"],\n",
    "                \"time\":      [\"00\", \"01\", \"02\", \"03\", \"04\", \"05\",\n",
    "                              \"06\", \"07\", \"08\", \"09\", \"10\", \"11\",\n",
    "                              \"12\", \"13\",\"14\", \"15\", \"16\", \"17\",\n",
    "                              \"18\", \"19\", \"20\",\"21\", \"22\", \"23\"]}\n",
    "    assume_fields = assumed_args.keys()\n",
    "\n",
    "    # input checks\n",
    "    for key in mandatory_fields:  # add mandatory arguments\n",
    "        if key not in kwargs: \n",
    "            raise ValueError(key+' not found in arguments, but is a mandatory field.')\n",
    "    \n",
    "    if kwargs['base_level'] == 'pressure' and 'pressure_level' not in kwargs:\n",
    "        raise IOError('base_level is pressure, but pressure_level not in kwargs')\n",
    "    \n",
    "    request_name = f\"reanalysis-era5-{kwargs.pop('base_level')}-levels\"\n",
    "    request = {}\n",
    "    for key in mandatory_fields:\n",
    "        request[key] = kwargs.pop(key)\n",
    "            \n",
    "    for key in list(kwargs):  # add optional arguments\n",
    "        request[key] = kwargs.pop(key)\n",
    "                                  \n",
    "    for key in assume_fields:  # assume some arguments if not given\n",
    "        if key not in request:\n",
    "            print(key, 'not found in arguments, assuming', key, '=', )\n",
    "    \n",
    "    return request\n",
    "                                  \n",
    "\n",
    "def cds_optimized_retrieval(save_to_folder, request: dict, time_start='2017:05', time_end='2017:07'):\n",
    "    c = cdsapi.Client()\n",
    "    \n",
    "    dataset_name = f\"reanalysis-era5-{request['base_level']}-levels\"\n",
    "    \n",
    "    # download era5 data with the cdsapi\n",
    "    # data request efficiency is highest when executed on a monthly basis\n",
    "    years = range(int(time_start.split(':')[0]), int(time_end.split(':')[0])+1)\n",
    "    months = range(int(time_start.split(':')[1]), int(time_end.split(':')[1])+1)\n",
    "\n",
    "    # loop over time range\n",
    "    for y in years:\n",
    "        for m in months:\n",
    "            # start a request for one month\n",
    "            # only execute if file does not exist\n",
    "            request = build_request(request)         \n",
    "            save_to_filename = f'{save_to_folder}/{dataset_name}_{request[\"variable\"]}_{y}_{\"%:02d\".format(m)}.nc'\n",
    "            \n",
    "            if not os.path.isfile(save_to_filename):\n",
    "                print(request); pass #c.retrieve(dataset_name, request, save_to_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "product_type not found in arguments, but is a mandatory field.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-05470897b1f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msave_to_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/raid/home/srvx7/lehre/users/a1254888/ipython/ml_flood/data/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcds_optimized_retrieval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_to_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2017:05'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2017:07'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-8783a7f991c5>\u001b[0m in \u001b[0;36mcds_optimized_retrieval\u001b[0;34m(save_to_folder, request, time_start, time_end)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# start a request for one month\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m# only execute if file does not exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0msave_to_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{save_to_folder}/{dataset_name}_{request[\"variable\"]}_{y}_{\"%:02d\".format(m)}.nc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-8783a7f991c5>\u001b[0m in \u001b[0;36mbuild_request\u001b[0;34m(kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmandatory_fields\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# add mandatory arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' not found in arguments, but is a mandatory field.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_level'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pressure'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'pressure_level'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: product_type not found in arguments, but is a mandatory field."
     ]
    }
   ],
   "source": [
    "request = dict(base_level='pressure', form='netcdf', area='50/7/47/20',\n",
    "               variable='geopotential', pressure_level='700', time_start='2017:05', time_end='2017:07')\n",
    "\n",
    "\n",
    "save_to_folder='/raid/home/srvx7/lehre/users/a1254888/ipython/ml_flood/data/'\n",
    "cds_optimized_retrieval(save_to_folder, request, time_start='2017:05', time_end='2017:07')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download request for the data of interest on pressure levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define areas of interest\n",
    "area_dict = {'danube': '50/7/47/20',\n",
    "             'asia': '55/-140/0/35',\n",
    "             'usa': '50/-125/25/-70'\n",
    "            }\n",
    "# choose area: 'danube', 'asia', 'usa'\n",
    "area = area_dict['danube']\n",
    "\n",
    "# variables\n",
    "variable = ['geopotential', 'temperature']#, 'specific humidity']\n",
    "\n",
    "# pressure levels\n",
    "base_level = 'pressure' # 'pressure' or 'single'\n",
    "pressure_level = ['850', '700', '500']\n",
    "\n",
    "\n",
    "# define time range: start end in the format YYYY:MM\n",
    "time_start = '1981:01' # full range start: '1981:01'\n",
    "time_end = '2017:12' # full range end: '2017:12'\n",
    "\n",
    "# create savename string\n",
    "variablestr = \"_\".join([x.replace(' ', '_') for x in variable])\n",
    "pressure_levelstr = \"_\".join([x for x in pressure_level])\n",
    "savename = f'era5_{variablestr}_{pressure_levelstr}'\n",
    "\n",
    "# retrieve data\n",
    "era5_retrieval(savename=savename, area=area, base_level=base_level, variable=variable,\n",
    "               pressure_level=pressure_level, time_start=time_start, time_end=time_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
